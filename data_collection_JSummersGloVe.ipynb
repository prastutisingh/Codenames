{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/prastutisingh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/prastutisingh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Top 50000 words from glove.42B.300d.zip were written to top_50000.txt\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from random import sample\n",
    "import copy\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load all data from massive embeddings file. You only need to do this once\n",
    "embeddings_all = {}\n",
    "with open(\"./top_50000.txt\", 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        tag = nltk.pos_tag([word])[0][1]\n",
    "        if tag in ['NN', 'NNP'] and len(word) != 1:\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_all[word] = vector\n",
    "\n",
    "# Load list of codenames words.\n",
    "codenames_words = []\n",
    "with open(\"./codenames_words.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        codenames_words.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose smaller sets of embeddings. \n",
    "def embeddings_size(embeddings_size, embeddings_all):\n",
    "    #embeddings_size is the length of the subset of embeddings\n",
    "    #embeddings_all is the embeddings from 50k top words\n",
    "    embeddings = {}\n",
    "    for x in list(embeddings_all)[0:embeddings_size]:\n",
    "        embeddings[x] = embeddings_all[x]\n",
    "    \n",
    "    #adds words from codenames that don't make it in the top XX words\n",
    "    for item in codenames_words:\n",
    "        if item not in embeddings:\n",
    "            try: \n",
    "                embeddings[item] = embeddings_all[item]\n",
    "            except KeyError: \n",
    "                codenames_words.remove(item)\n",
    "            \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_1000 = embeddings_size(1000, embeddings_all)\n",
    "#embeddings_5000 = embeddings_size(5000, embeddings_all)\n",
    "embeddings_10000 = embeddings_size(10000, embeddings_all)\n",
    "embeddings_25000 = embeddings_size(25000, embeddings_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def distance(embeddings, word, reference):\n",
    "    return spatial.distance.cosine(embeddings[word], embeddings[reference])\n",
    "\n",
    "def closest_words(embeddings, reference):\n",
    "    return sorted(embeddings.keys(), key=lambda w: distance(embeddings, w, reference))\n",
    "\n",
    "def goodness(embeddings, word, answers, bad):\n",
    "#     if word in answers + bad: return -999\n",
    "    return sum([distance(embeddings, word, b) for b in bad]) - 4.0 * sum([distance(embeddings, word, a) for a in answers])\n",
    "\n",
    "def minimax(embeddings, word, answers, bad):\n",
    "#     if word in answers + bad: return -999\n",
    "    return min([distance(embeddings, word, b) for b in bad]) - max([distance(embeddings, word, a) for a in answers])\n",
    "\n",
    "def candidates(embeddings, answers, bad, size=20):\n",
    "    best = sorted(embeddings.keys(), key=lambda w: -1 * goodness(embeddings, w, answers, bad))\n",
    "    res = [(str(i + 1), \"{0:.2f}\".format(minimax(embeddings, w, answers, bad)), w) for i, w in enumerate(sorted(best[:250], key=lambda w: -1 * minimax(embeddings, w, answers, bad))[:size])]\n",
    "    return [c[2] for c in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tong',\n",
       " 'wok',\n",
       " 'guan',\n",
       " 'kitchenware',\n",
       " 'nippon',\n",
       " 'torino',\n",
       " 'thanh',\n",
       " 'jian',\n",
       " 'bao',\n",
       " 'jia',\n",
       " 'omelette',\n",
       " 'kan',\n",
       " 'quan',\n",
       " 'sheng',\n",
       " 'ge',\n",
       " 'savoy',\n",
       " 'lyon',\n",
       " 'shu',\n",
       " 'intercontinental',\n",
       " 'buffet']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = [\"iron\", \"ham\", \"beijing\"]\n",
    "bad = [\"fall\", \"witch\", \"note\", \"cat\", \"bear\", \"ambulance\"]\n",
    "candidates(embeddings_all, answers, bad, size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to help with word + scores (not necessary for data collection)...\n",
    "from itertools import zip_longest\n",
    "\n",
    "def grouper(n, iterable, fillvalue=None):\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(fillvalue=fillvalue, *args)\n",
    "\n",
    "def tabulate(data):\n",
    "    data = list(grouper(10, data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from itertools import combinations \n",
    "\n",
    "def generate_single_example(codenames_words, embeddings):\n",
    "    # Generates a single example (good words, bad words, top ten clues)\n",
    "    while True: \n",
    "        good = sample(codenames_words, 3)\n",
    "        combo_list = list(combinations(good, 2)) \n",
    "        threshold_list = [distance(embeddings_all, item[0], item[1]) > 0.75 for item in combo_list]\n",
    "        if all(good): \n",
    "            break\n",
    "    \n",
    "    bad = sample(codenames_words, 6)\n",
    "    \n",
    "#     for i in range(len(bad)): \n",
    "#         while bad[i] in good: \n",
    "#             bad[i] = sample(codenames_words, 1)\n",
    "    \n",
    "    print(good)\n",
    "    print(bad)\n",
    "    clues = candidates(embeddings, good, bad)\n",
    "    \n",
    "    for item in good: \n",
    "        if item in clues:\n",
    "            clues.remove(item)\n",
    "\n",
    "    return good, bad, clues[:10]\n",
    "\n",
    "def write_n_examples(codenames_words, embeddings, n, filename): \n",
    "    # Generates n examples and writes them to filename\n",
    "    output_file = open(filename, 'w')\n",
    "    \n",
    "    for i in range(n): \n",
    "        good, bad, clues = generate_single_example(codenames_words, embeddings)\n",
    "        word_string = ', '.join(good + bad + clues) + '\\n'\n",
    "        output_file.write(str(i) + '.' + word_string)\n",
    "    \n",
    "    output_file.close()\n",
    "    \n",
    "# write_n_examples(codenames_words, embeddings_1000, 10, 'test_examples.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916841804981232"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(embeddings_all, 'ham', 'iron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_n_examples(filename):\n",
    "    '''Reads filename of good, bad, clues examples into a three-dimensional array. \n",
    "    To access the 0th example: data[0]\n",
    "    To access the good words (in list form) from the 1st example: data[1][0]\n",
    "        good words list - 0\n",
    "        bad words list - 1\n",
    "        clue words list - 2\n",
    "    To access the first clue word from the 1st example: data[1][2][0]'''\n",
    "    file = open(filename, 'r')\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for line in file: \n",
    "        full_list = line.strip('\\n').split(',')\n",
    "        good = full_list[:3]\n",
    "        bad = full_list[3:9]\n",
    "        clues = full_list[9:]\n",
    "        data.append([good, bad, clues])\n",
    "        \n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hood', 'kid', 'rome']\n",
      "['bow', 'truck', 'death', 'box', 'worm', 'bond']\n",
      "['undertaker', 'death', 'club']\n",
      "['kangaroo', 'orange', 'tower', 'bark', 'phoenix', 'shot']\n",
      "['wall', 'fish', 'pilot']\n",
      "['triangle', 'doctor', 'nurse', 'dog', 'millionaire', 'tower']\n",
      "['lemon', 'opera', 'lap']\n",
      "['sprint', 'hospital', 'belt', 'alien', 'mammoth', 'time']\n",
      "['triangle', 'mug', 'lock']\n",
      "['mouth', 'telescope', 'berry', 'belt', 'box', 'africa']\n",
      "['truck', 'kangaroo', 'opera']\n",
      "['rock', 'lock', 'staff', 'eye', 'ivory', 'revolution']\n",
      "['slip', 'whip', 'mercury']\n",
      "['dwarf', 'bark', 'note', 'lab', 'slip', 'root']\n",
      "['box', 'africa', 'novel']\n",
      "['knife', 'himalaya', 'kiwi', 'lap', 'lab', 'doctor']\n",
      "['europe', 'triangle', 'time']\n",
      "['bank', 'cell', 'giant', 'antarctica', 'stick', 'sprint']\n",
      "['fish', 'lap', 'worm']\n",
      "['lock', 'horseshoe', 'knight', 'night', 'jam', 'turkey']\n"
     ]
    }
   ],
   "source": [
    "#write_n_examples(codenames_words, embeddings_10000, 10, 'examples_10000_vocab.txt')\n",
    "write_n_examples(codenames_words, embeddings_25000, 10, 'examples_25000_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_n_examples(codenames_words, embeddings_5000, 100, 'examples_5000_vocab.txt')\n",
    "write_n_examples(codenames_words, embeddings_10000, 100, 'examples_10000_vocab.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
